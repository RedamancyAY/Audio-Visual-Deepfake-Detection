{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e329d-4fb9-4e5b-b24d-e6ca29c5ba75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabfa64-ff0f-430f-9bad-87c0a2a3dfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import functools\n",
    "import hashlib\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pandarallel import pandarallel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4b09d-1e05-48b6-9645-1b09a100a1a1",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "outputs": [],
   "source": [
    "from .utils import generate_paths, get_video_metadata, split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf39c0-a21c-4545-90aa-337708833b14",
   "metadata": {
    "tags": [
     "style-activity",
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "from utils import generate_paths, get_video_metadata, split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c7f73-da4d-4474-b9c5-9f9055686c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_name(path):\n",
    "    if \"VoxCeleb2\" in path:\n",
    "        name = path.split(\"VoxCeleb2/\")[1]\n",
    "    else:\n",
    "        name = \"-\".join(path.split(\"/\")[-5:])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74cf9f-d2d3-427d-a3dc-4c843c14fcf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_to_person(path):\n",
    "    if \"VoxCeleb2\" in path:\n",
    "        name = path.split(\"VoxCeleb2/\")[1].split(\"-\")[0]\n",
    "    else:\n",
    "        name = path.split(\"/\")[-2]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5108a6-e59d-4008-bef9-97064cb6809c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_splits(total_data, splits):\n",
    "    def _help(data):\n",
    "        all_items = sorted(list(set(list(data[\"person\"]))))\n",
    "        L = len(all_items)\n",
    "        train = int(L * splits[0])\n",
    "        val = int(L * splits[1])\n",
    "        test = L - train - val\n",
    "        res = {}\n",
    "        res[\"train\"] = data[data[\"person\"].isin(all_items[0:train])].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        res[\"val\"] = data[\n",
    "            data[\"person\"].isin(all_items[train : train + val])\n",
    "        ].reset_index(drop=True)\n",
    "        res[\"test\"] = data[data[\"person\"].isin(all_items[train + val :])].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        for x in res.keys():\n",
    "            print(len(res[x]))\n",
    "        return argparse.Namespace(**res)\n",
    "\n",
    "    res_org = _help(total_data.query(\"VoxCeleb2==0\"))\n",
    "    res_add = _help(total_data.query(\"VoxCeleb2==1\"))\n",
    "    return argparse.Namespace(\n",
    "        train=pd.concat([res_org.train, res_add.train]),\n",
    "        val=pd.concat([res_org.val, res_add.val]),\n",
    "        test=pd.concat([res_org.test, res_add.test]),\n",
    "    )\n",
    "    return argparse.Namespace(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7865a801-62ca-41c9-a4a3-fbbc5eabde3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T08:12:36.322659Z",
     "iopub.status.busy": "2023-04-14T08:12:36.322109Z",
     "iopub.status.idle": "2023-04-14T08:12:36.366237Z",
     "shell.execute_reply": "2023-04-14T08:12:36.365641Z",
     "shell.execute_reply.started": "2023-04-14T08:12:36.322632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FakeAVCeleb:\n",
    "    \"\"\"deal with the dataset FakeAVCeleb\"\"\"\n",
    "\n",
    "    def __init__(self, root_path: str, data_path):\n",
    "        if root_path.endswith(os.sep):\n",
    "            root_path = root_path[:-1]\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "\n",
    "        self.path_dataset_info = os.path.join(root_path, \"dataset_info.csv\")\n",
    "        self.data = self.read_dataset_info()\n",
    "\n",
    "        assert len(self.data) > 0, \"There is no video in %s\" % root_path\n",
    "        assert len(self.data) == 21544 + 2000\n",
    "        self.data = generate_paths(self.data, data_path=data_path)\n",
    "\n",
    "    def read_dataset_info(self):\n",
    "        if not os.path.exists(self.path_dataset_info):\n",
    "            data = self.init_dataset_info()\n",
    "        else:\n",
    "            data = pd.read_csv(self.path_dataset_info)\n",
    "        return data\n",
    "\n",
    "    def init_dataset_info(self) -> pd.DataFrame:\n",
    "        paths = []\n",
    "        for path, dir_list, file_list in os.walk(self.root_path):\n",
    "            for file_name in file_list:\n",
    "                if file_name.endswith(\"mp4\"):\n",
    "                    paths.append(os.path.join(path, file_name))\n",
    "        print(len(paths))\n",
    "        data = pd.DataFrame(sorted(paths), columns=[\"path\"])\n",
    "        data[\"video_label\"] = data[\"path\"].apply(lambda x: 0 if \"FakeVideo\" in x else 1)\n",
    "        data[\"audio_label\"] = data[\"path\"].apply(lambda x: 0 if \"FakeAudio\" in x else 1)\n",
    "        data[\"label\"] = data[\"path\"].apply(\n",
    "            lambda x: 1 if (\"RealVideo-RealAudio\" in x or \"VoxCeleb2\" in x) else 0\n",
    "        )\n",
    "        ## 3. get video info\n",
    "        print(\"read video info from all videos:\")\n",
    "        data = get_video_metadata(data)\n",
    "\n",
    "        data[\"VoxCeleb2\"] = data[\"path\"].apply(lambda x: 1 if \"VoxCeleb2\" in x else 0)\n",
    "        data[\"name\"] = data[\"path\"].apply(path_to_name)\n",
    "        assert len(set(list(dataset.data[\"name\"]))) == len(data)\n",
    "\n",
    "        data[\"person\"] = data[\"path\"].apply(path_to_person)\n",
    "        meta_data = pd.read_excel(dataset.root_path + \"/meta_data.xlsx\")\n",
    "        meta_data[\"path2\"] = meta_data.apply(\n",
    "            lambda x: x[\"path2\"] + \"/\" + x[\"path\"], axis=1\n",
    "        )\n",
    "        meta_data[\"name\"] = meta_data[\"path2\"].apply(path_to_name)\n",
    "        meta_data = meta_data[[\"name\", \"method\"]]\n",
    "        meta_data = meta_data.drop_duplicates([\"name\"])\n",
    "\n",
    "        data = pd.merge(data, meta_data, on=\"name\", how=\"left\")\n",
    "        data[\"method\"] = data[\"method\"].fillna(\"real\")\n",
    "\n",
    "        data.to_csv(self.path_dataset_info, index=False)\n",
    "        return data\n",
    "\n",
    "    def get_splits(\n",
    "        self,\n",
    "        train_num: list,\n",
    "        append_train_num=0,\n",
    "        splits=[0.75, 0.1, 0.15],\n",
    "        person_splits=False,\n",
    "        method=None,\n",
    "    ) -> list:\n",
    "        \"\"\"split the train and test datasets for developping a deep model\n",
    "\n",
    "        args:\n",
    "            train_num: the numbers of four types (`self.AV_types`) videos in train set\n",
    "            val_num: the numbers of four types (`self.AV_types`) videos in validation set\n",
    "            test_num: the numbers of four types (`self.AV_types`) videos in test set\n",
    "            append_train_num: the extra number of RealVideo-RealAudio videos from VoxCeleb2\n",
    "        \"\"\"\n",
    "        data = self.data\n",
    "        assert len(train_num) == 4\n",
    "\n",
    "        if method is not None:\n",
    "            data = data[\n",
    "                data[\"method\"].isin([method, method + \"-wav2lip\", \"rtvc\", \"real\"])\n",
    "            ]\n",
    "\n",
    "        lens = [\n",
    "            len(\n",
    "                data.query(\n",
    "                    \"VoxCeleb2 == 0 & video_label == {} & audio_label == {}\".format(\n",
    "                        a, b\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            for (a, b) in [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "        ]\n",
    "\n",
    "        data_selected = pd.concat(\n",
    "            [\n",
    "                data.query(\n",
    "                    \"VoxCeleb2 == 0 & video_label == {} & audio_label == {}\".format(\n",
    "                        a, b\n",
    "                    )\n",
    "                ).sample(min(lens[i], train_num[i]), random_state=42)\n",
    "                for i, (a, b) in enumerate([(0, 0), (0, 1), (1, 0), (1, 1)])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if append_train_num > 0:\n",
    "            data_added = data.query(\"VoxCeleb2 == 1\").sample(\n",
    "                append_train_num, random_state=42\n",
    "            )\n",
    "            data_selected = pd.concat([data_selected, data_added])\n",
    "\n",
    "        # print(len(data), lens, train_num, method, len(data_selected))\n",
    "        \n",
    "        \n",
    "        if person_splits:\n",
    "            return custom_splits(data_selected, splits=splits)\n",
    "        else:\n",
    "            return split_datasets(data_selected, splits=splits)\n",
    "\n",
    "    def get_splits_by_method(\n",
    "        self,\n",
    "        train_num: list,\n",
    "        append_train_num=0,\n",
    "        splits=[0.75, 0.1, 0.15],\n",
    "        method=\"fsgan\",\n",
    "    ) -> list:\n",
    "        \"\"\"split the train and test datasets for developping a deep model\n",
    "\n",
    "        args:\n",
    "            train_num: the numbers of four types (`self.AV_types`) videos in train set\n",
    "            val_num: the numbers of four types (`self.AV_types`) videos in validation set\n",
    "            test_num: the numbers of four types (`self.AV_types`) videos in test set\n",
    "            append_train_num: the extra number of RealVideo-RealAudio videos from VoxCeleb2\n",
    "        \"\"\"\n",
    "        data = self.data\n",
    "        assert len(train_num) == 4\n",
    "\n",
    "        assert method in [\"fsgan\", \"wav2lip\", \"faceswap\"]\n",
    "        data_fsgan, data_wav2lip, data_faceswap = [\n",
    "            self.get_splits(\n",
    "                train_num=train_num,\n",
    "                append_train_num=append_train_num,\n",
    "                splits=splits,\n",
    "                method=_method,\n",
    "            )\n",
    "            for _method in [\"fsgan\", \"wav2lip\", \"faceswap\"]\n",
    "        ]\n",
    "        # for item in [data_fsgan, data_wav2lip, data_faceswap]:\n",
    "            # print(len(item.train), len(item.val), len(item.test))\n",
    "        \n",
    "\n",
    "        if method == \"fsgan\":\n",
    "            return argparse.Namespace(\n",
    "                train=data_fsgan.train,\n",
    "                val=data_fsgan.val,\n",
    "                test1=data_wav2lip.test,\n",
    "                test2=data_faceswap.test,\n",
    "            )\n",
    "        elif method == \"wav2lip\":\n",
    "            return argparse.Namespace(\n",
    "                train=data_wav2lip.train,\n",
    "                val=data_wav2lip.val,\n",
    "                test1=data_fsgan.test,\n",
    "                test2=data_faceswap.test,\n",
    "            )\n",
    "        else:\n",
    "            return argparse.Namespace(\n",
    "                train=data_faceswap.train,\n",
    "                val=data_faceswap.val,\n",
    "                test1=data_wav2lip.test,\n",
    "                test2=data_fsgan.test,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
