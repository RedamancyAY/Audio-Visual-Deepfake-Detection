{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ae88f-926f-40f4-85d1-01df03c33eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50694e5c-e7a1-4025-9d6b-ac12ccbbc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.augmentations.transforms as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e15ed3-6caa-495a-a099-42f21e2f3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .dataset import DF_TIMIT, DFDC, FakeAVCeleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae4b3a-f726-432b-a66c-a9687fd3d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .utils.preprocessing import Read_audio, Read_video\n",
    "from .utils.tools import DeepFake_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6caf5-cfcd-4e80-8859-a64c55b729b4",
   "metadata": {
    "tags": [
     "active-ipynb",
     "style-activity"
    ]
   },
   "outputs": [],
   "source": [
    "from dataset import DF_TIMIT, DFDC, FakeAVCeleb\n",
    "from utils.tools import DeepFake_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914fadcc-1251-491c-a64c-97bf193aac8a",
   "metadata": {},
   "source": [
    "# Help function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3143b2-547e-4a5c-afd2-258babb18fc3",
   "metadata": {},
   "source": [
    "## 提取视频帧、秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c06bd-0b43-4c39-83b6-440379aaf1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_video_to_3sec(data):\n",
    "    \"\"\"\n",
    "    每个视频抽N帧，组合成一个新的dataframe\n",
    "\n",
    "    Args:\n",
    "        data: 一个dataframe，长度就是数据集的长度，path指定视频的路径\n",
    "        video_n_frames: 每个视频的长度\n",
    "    Return:\n",
    "        一个新的dataframe，frame_id列指定视频的哪一帧\n",
    "    \"\"\"\n",
    "    data['n_sec'] = data.apply(lambda x: x['n_frames'] // x['fps'], axis=1)\n",
    "    max_sec = data['n_sec'].max()\n",
    "    \n",
    "    datas = []\n",
    "    for i in range(max_sec//3):\n",
    "        _data = data.copy()\n",
    "        _data[\"start_sec\"] = i * 3\n",
    "        _data['end_sec'] = i * 3 + 3\n",
    "        datas.append(_data)\n",
    "    datas = pd.concat(datas, ignore_index=True)\n",
    "    datas = datas.query('end_sec <= n_sec ')\n",
    "    print(\"Extract 3 sec for each video: \", len(data), ' -> ', len(datas))\n",
    "    return datas.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b1b40-8cdb-46ad-b023-685869ed0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_video_to_frame(data, video_n_frames):\n",
    "    \"\"\"\n",
    "    每个视频抽N帧，组合成一个新的dataframe\n",
    "\n",
    "    Args:\n",
    "        data: 一个dataframe，长度就是数据集的长度，path指定视频的路径\n",
    "        video_n_frames: 每个视频的长度\n",
    "    Return:\n",
    "        一个新的dataframe，frame_id列指定视频的哪一帧\n",
    "    \"\"\"\n",
    "    datas = []\n",
    "    for i in range(video_n_frames):\n",
    "        _data = data.copy()\n",
    "        _data[\"frame_id\"] = i\n",
    "        datas.append(_data)\n",
    "    return pd.concat(datas, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963fb66-4af9-40ed-ac97-1562423bcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_video_to_sec(data, max_sec=3):\n",
    "    \"\"\"\n",
    "    每个视频抽N秒，组合成一个新的dataframe\n",
    "\n",
    "    Args:\n",
    "        data: 一个dataframe，长度就是数据集的长度，path指定视频的路径\n",
    "        video_n_frames: 每个视频的长度\n",
    "    Return:\n",
    "        一个新的dataframe，frame_id列指定视频的哪一帧\n",
    "    \"\"\"\n",
    "    datas = []\n",
    "    for i in range(max_sec):\n",
    "        _data = data.copy()\n",
    "        _data[\"sec_id\"] = i + 1\n",
    "        datas.append(_data)\n",
    "    _data = pd.concat(datas, ignore_index=True)\n",
    "    print(len(_data))\n",
    "    # _data['sec'] = _data.apply(lambda x: x['n_frames'] // x['fps'], axis=1)\n",
    "    # _data = _data[_data['sec'] > _data['sec_id']]\n",
    "    _data = _data[_data[\"n_frames\"] >= 75]\n",
    "    print(\"原始dataframe的长度为: \", len(data), \", 抽秒之后: \", len(_data))\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c9f52-c6fe-4627-a8e1-89999406d924",
   "metadata": {},
   "source": [
    "## panda dataframe to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea54a25-2d47-4e79-a494-a385dcebd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2dataloader(data_splits, cfg, cfg_aug, custom_collect_fn=None, sec3=False):\n",
    "    \"\"\"\n",
    "    convert dataframes of `train, val, test` into dataloaders\n",
    "\n",
    "    Args:\n",
    "        datasets: [train, val, test] or [train, test]\n",
    "        cfg: total config\n",
    "\n",
    "    Return:\n",
    "        a dict for dataloaders\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "    data_splits = vars(data_splits)\n",
    "    for item in [\"train\", \"val\", \"test\", \"test1\", \"test2\"]:\n",
    "        if item in data_splits.keys():\n",
    "            datasets.append(data_splits[item])\n",
    "    # if \"val\" in data_splits:\n",
    "    #     datasets = [data_splits.train, data_splits.val, data_splits.test]\n",
    "    # else:\n",
    "    #     datasets = [data_splits.train, data_splits.test]\n",
    "\n",
    "    batch_size = [cfg.batch_size] + [cfg.test_batch_size] * (len(datasets) - 1)\n",
    "    res = []\n",
    "    for i, (dataset, _batch_size) in enumerate(zip(datasets, batch_size)):\n",
    "        \n",
    "        if sec3:\n",
    "            dataset = df_video_to_3sec(dataset)\n",
    "        \n",
    "        \n",
    "        if cfg.train_on_frame and i == 0:\n",
    "            dataset = df_video_to_frame(dataset, cfg.video_n_frames)\n",
    "\n",
    "        if cfg.train_on_sec:\n",
    "            dataset = df_video_to_sec(dataset, max_sec=3)\n",
    "\n",
    "        res.append(\n",
    "            DataLoader(\n",
    "                DeepFake_Dataset(\n",
    "                    dataset,\n",
    "                    cfg,\n",
    "                    cfg_aug=cfg_aug if i == 0 else None,\n",
    "                    train=(i == 0),\n",
    "                    custom_collect_fn=custom_collect_fn,\n",
    "                ),\n",
    "                batch_size=_batch_size,\n",
    "                num_workers=cfg.num_workers,\n",
    "                pin_memory=True,\n",
    "                shuffle=True if i == 0 else False,\n",
    "                prefetch_factor=2,\n",
    "                collate_fn=None,\n",
    "            )\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6371a-338a-482c-a5b5-ca91b1138745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    # your batching code here\n",
    "    data = {}\n",
    "    data[\"video\"] = torch.stack([b[0][\"video\"] for b in batch])\n",
    "    data[\"audio\"] = torch.stack([b[0][\"audio\"] for b in batch])\n",
    "    data[\"video_path\"] = [b[0][\"video_path\"] for b in batch]\n",
    "    label = {}\n",
    "    label[\"label\"] = torch.stack([torch.tensor(b[1][\"label\"]) for b in batch])\n",
    "    label[\"video_label\"] = torch.stack(\n",
    "        [torch.tensor(b[1][\"video_label\"]) for b in batch]\n",
    "    )\n",
    "    label[\"audio_label\"] = torch.stack(\n",
    "        [torch.tensor(b[1][\"audio_label\"]) for b in batch]\n",
    "    )\n",
    "    # for b in batch:\n",
    "    # print(b[0]['video'].shape)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce3238-d127-490e-9cf8-f5f41ad59360",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadc725-b84e-4fb5-bb14-11b86732f483",
   "metadata": {},
   "source": [
    "## FakeAVCeleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cab3b-1a13-455c-b7ca-11914feae5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FakeAVCeleb(cfg, cfg_aug, custom_collect_fn=None):\n",
    "    dataset = FakeAVCeleb(\n",
    "        root_path=cfg.FakeAVCeleb.root_path, data_path=cfg.FakeAVCeleb.data_path\n",
    "    )\n",
    "\n",
    "    if cfg.FakeAVCeleb.quality != 0:\n",
    "        print(\n",
    "            \"Compress video using H264 with quantiztion rate %d\"\n",
    "            % cfg.FakeAVCeleb.quality\n",
    "        )\n",
    "        dataset.data[\"video_path\"] == dataset.data[\"video_path\"].apply(\n",
    "            lambda x: x.replace(\"/video/\", \"/video%d/\" % cfg.FakeAVCeleb.quality)\n",
    "        )\n",
    "\n",
    "    if cfg.FakeAVCeleb.method is None:\n",
    "        data_splits = dataset.get_splits(\n",
    "            train_num=cfg.FakeAVCeleb.train_num,\n",
    "            append_train_num=cfg.FakeAVCeleb.append_train_num,\n",
    "            splits=cfg.FakeAVCeleb.splits,\n",
    "            person_splits=False,\n",
    "        )\n",
    "    else:\n",
    "        data_splits = dataset.get_splits_by_method(\n",
    "            train_num=cfg.FakeAVCeleb.train_num,\n",
    "            append_train_num=cfg.FakeAVCeleb.append_train_num,\n",
    "            splits=cfg.FakeAVCeleb.splits,\n",
    "            method=cfg.FakeAVCeleb.method,\n",
    "        )\n",
    "    return data2dataloader(\n",
    "        data_splits, cfg, cfg_aug, custom_collect_fn=custom_collect_fn, sec3=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47874f0-5c46-4ef2-b7d1-988ff8116894",
   "metadata": {},
   "source": [
    "## DF TIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4adc4-432f-460c-a0af-e436c7590f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DF_TIMIT(cfg, cfg_aug, custom_collect_fn=None):\n",
    "    data_splits = DF_TIMIT(\n",
    "        root_path=cfg.DF_TIMIT.root_path,\n",
    "        data_path=cfg.DF_TIMIT.data_path,\n",
    "    ).get_splits(\n",
    "        splits=cfg.DF_TIMIT.splits,\n",
    "        video_quality=cfg.DF_TIMIT.video_quality,\n",
    "    )\n",
    "    return data2dataloader(\n",
    "        data_splits, cfg, cfg_aug, custom_collect_fn=custom_collect_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d12ae-7bee-4505-8bfb-a41e72e35208",
   "metadata": {},
   "source": [
    "## DFDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696f861-b940-442c-97af-9f4582ea2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DFDC(cfg, cfg_aug, custom_collect_fn=None):\n",
    "    data_splits = DFDC(\n",
    "        root_path=cfg.DFDC.root_path,\n",
    "        data_path=cfg.DFDC.data_path,\n",
    "        face_detect_method=cfg.face_detect_method,\n",
    "    ).get_splits(\n",
    "        splits=cfg.DFDC.train_splits,\n",
    "    )\n",
    "    return data2dataloader(\n",
    "        data_splits, cfg, cfg_aug, custom_collect_fn=custom_collect_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a1170-7e97-4ac0-b11b-2c1527c4065c",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b20a6-9409-41a5-8f85-5e1a7e7da097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(cfg, cfg_aug, custom_collect_fn=None):\n",
    "    # read_func, aug_func = build_read_aug_func(cfg)\n",
    "\n",
    "    if \"FakeAVCeleb\" in cfg.name:\n",
    "        return get_FakeAVCeleb(cfg, cfg_aug, custom_collect_fn=custom_collect_fn)\n",
    "    elif cfg.name == \"DF_TIMIT\":\n",
    "        return get_DF_TIMIT(cfg, cfg_aug, custom_collect_fn=custom_collect_fn)\n",
    "    elif cfg.name == \"DFDC\":\n",
    "        return get_DFDC(cfg, cfg_aug, custom_collect_fn=custom_collect_fn)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
